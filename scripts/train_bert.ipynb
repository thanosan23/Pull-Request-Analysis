{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all the libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import polars as pl\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import polars as pl\n",
    "\n",
    "import xgboost as xgb\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data\n",
    "data = pd.read_csv(\"../data/pullreq_with_code.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the rows with no code\n",
    "data = data[data[\"added_code\"].astype(str) != \"None\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only get the merged data, and drop any data that have n/a as gender\n",
    "rejected_data = data.loc[data['merged_or_not'] == 0]\n",
    "rejected_data = rejected_data.loc[rejected_data['contrib_gender'].notna()]\n",
    "\n",
    "# drop the columns that are not needed\n",
    "rejected_data = rejected_data.drop(['ownername', 'reponame', 'id', 'project_id', 'github_id', 'creator_id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign smaller class (female) 1\n",
    "gender_dict = {'male': 0, 'female': 1}\n",
    "\n",
    "rejected_data['contrib_gender'] = rejected_data['contrib_gender'].map(gender_dict)\n",
    "df_majority = rejected_data[rejected_data['contrib_gender']==0]\n",
    "df_minority = rejected_data[rejected_data['contrib_gender']==1]\n",
    "\n",
    "df_majority_downsampled = df_majority.sample(len(df_minority), replace=False)\n",
    "\n",
    "rejected_data = pd.concat([df_majority_downsampled, df_minority])\n",
    "\n",
    "X = rejected_data['added_code']\n",
    "Y = rejected_data['contrib_gender']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the tokenizer and model for codebert\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/codebert-base\")\n",
    "codebert_model = AutoModel.from_pretrained(\"microsoft/codebert-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/1644 [00:04<39:19,  1.44s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m code \u001b[38;5;129;01min\u001b[39;00m tqdm(X):\n\u001b[1;32m      4\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m tokenizer(code, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 5\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m codebert_model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs) \u001b[38;5;66;03m# inputs = input_ids, attention_mask\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     X_embeddings\u001b[38;5;241m.\u001b[39mappend(outputs\u001b[38;5;241m.\u001b[39mlast_hidden_state[:, \u001b[38;5;241m0\u001b[39m, :]\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy())\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch2/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch2/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch2/lib/python3.12/site-packages/transformers/models/roberta/modeling_roberta.py:835\u001b[0m, in \u001b[0;36mRobertaModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    826\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m    828\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(\n\u001b[1;32m    829\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m    830\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    833\u001b[0m     past_key_values_length\u001b[38;5;241m=\u001b[39mpast_key_values_length,\n\u001b[1;32m    834\u001b[0m )\n\u001b[0;32m--> 835\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(\n\u001b[1;32m    836\u001b[0m     embedding_output,\n\u001b[1;32m    837\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mextended_attention_mask,\n\u001b[1;32m    838\u001b[0m     head_mask\u001b[38;5;241m=\u001b[39mhead_mask,\n\u001b[1;32m    839\u001b[0m     encoder_hidden_states\u001b[38;5;241m=\u001b[39mencoder_hidden_states,\n\u001b[1;32m    840\u001b[0m     encoder_attention_mask\u001b[38;5;241m=\u001b[39mencoder_extended_attention_mask,\n\u001b[1;32m    841\u001b[0m     past_key_values\u001b[38;5;241m=\u001b[39mpast_key_values,\n\u001b[1;32m    842\u001b[0m     use_cache\u001b[38;5;241m=\u001b[39muse_cache,\n\u001b[1;32m    843\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[1;32m    844\u001b[0m     output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[1;32m    845\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[1;32m    846\u001b[0m )\n\u001b[1;32m    847\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    848\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch2/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch2/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch2/lib/python3.12/site-packages/transformers/models/roberta/modeling_roberta.py:524\u001b[0m, in \u001b[0;36mRobertaEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    513\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    514\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    515\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    521\u001b[0m         output_attentions,\n\u001b[1;32m    522\u001b[0m     )\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 524\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m layer_module(\n\u001b[1;32m    525\u001b[0m         hidden_states,\n\u001b[1;32m    526\u001b[0m         attention_mask,\n\u001b[1;32m    527\u001b[0m         layer_head_mask,\n\u001b[1;32m    528\u001b[0m         encoder_hidden_states,\n\u001b[1;32m    529\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    530\u001b[0m         past_key_value,\n\u001b[1;32m    531\u001b[0m         output_attentions,\n\u001b[1;32m    532\u001b[0m     )\n\u001b[1;32m    534\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch2/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch2/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch2/lib/python3.12/site-packages/transformers/models/roberta/modeling_roberta.py:413\u001b[0m, in \u001b[0;36mRobertaLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    403\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    410\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m    411\u001b[0m     \u001b[38;5;66;03m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[1;32m    412\u001b[0m     self_attn_past_key_value \u001b[38;5;241m=\u001b[39m past_key_value[:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 413\u001b[0m     self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattention(\n\u001b[1;32m    414\u001b[0m         hidden_states,\n\u001b[1;32m    415\u001b[0m         attention_mask,\n\u001b[1;32m    416\u001b[0m         head_mask,\n\u001b[1;32m    417\u001b[0m         output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[1;32m    418\u001b[0m         past_key_value\u001b[38;5;241m=\u001b[39mself_attn_past_key_value,\n\u001b[1;32m    419\u001b[0m     )\n\u001b[1;32m    420\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    422\u001b[0m     \u001b[38;5;66;03m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch2/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch2/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch2/lib/python3.12/site-packages/transformers/models/roberta/modeling_roberta.py:340\u001b[0m, in \u001b[0;36mRobertaAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    331\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    332\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    338\u001b[0m     output_attentions: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    339\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[0;32m--> 340\u001b[0m     self_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself(\n\u001b[1;32m    341\u001b[0m         hidden_states,\n\u001b[1;32m    342\u001b[0m         attention_mask,\n\u001b[1;32m    343\u001b[0m         head_mask,\n\u001b[1;32m    344\u001b[0m         encoder_hidden_states,\n\u001b[1;32m    345\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    346\u001b[0m         past_key_value,\n\u001b[1;32m    347\u001b[0m         output_attentions,\n\u001b[1;32m    348\u001b[0m     )\n\u001b[1;32m    349\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(self_outputs[\u001b[38;5;241m0\u001b[39m], hidden_states)\n\u001b[1;32m    350\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (attention_output,) \u001b[38;5;241m+\u001b[39m self_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch2/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch2/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch2/lib/python3.12/site-packages/transformers/models/roberta/modeling_roberta.py:266\u001b[0m, in \u001b[0;36mRobertaSelfAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    263\u001b[0m     attention_scores \u001b[38;5;241m=\u001b[39m attention_scores \u001b[38;5;241m+\u001b[39m attention_mask\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# Normalize the attention scores to probabilities.\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m attention_probs \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39msoftmax(attention_scores, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    268\u001b[0m \u001b[38;5;66;03m# This is actually dropping out entire tokens to attend to, which might\u001b[39;00m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;66;03m# seem a bit unusual, but is taken from the original Transformer paper.\u001b[39;00m\n\u001b[1;32m    270\u001b[0m attention_probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(attention_probs)\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch2/lib/python3.12/site-packages/torch/nn/functional.py:1858\u001b[0m, in \u001b[0;36msoftmax\u001b[0;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[1;32m   1856\u001b[0m     dim \u001b[38;5;241m=\u001b[39m _get_softmax_dim(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim(), _stacklevel)\n\u001b[1;32m   1857\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1858\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msoftmax(dim)\n\u001b[1;32m   1859\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1860\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msoftmax(dim, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# get the embeddings for each code\n",
    "X_embeddings = []\n",
    "for code in tqdm(X):\n",
    "    inputs = tokenizer(code, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    outputs = codebert_model(**inputs) # inputs = input_ids, attention_mask\n",
    "    X_embeddings.append(outputs.last_hidden_state[:, 0, :].detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape the embeddings\n",
    "X_embeddings = np.array(X_embeddings)\n",
    "X_embeddings = X_embeddings.reshape(-1, codebert_model.config.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size) \n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size) \n",
    "        self.fc3 = nn.Linear(hidden_size, hidden_size) \n",
    "        self.fc4 = nn.Linear(hidden_size, num_classes)  \n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc3(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc4(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8162it [01:15, 107.70it/s]\n",
      "500it [00:00, 3199.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Train Loss: 0.0000, Test Accuracy: 9.20%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      1.00      0.17        46\n",
      "           1       0.00      0.00      0.00       454\n",
      "\n",
      "    accuracy                           0.09       500\n",
      "   macro avg       0.05      0.50      0.08       500\n",
      "weighted avg       0.01      0.09      0.02       500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8162it [01:16, 106.82it/s]\n",
      "500it [00:00, 3175.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20], Train Loss: 0.0001, Test Accuracy: 9.20%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      1.00      0.17        46\n",
      "           1       0.00      0.00      0.00       454\n",
      "\n",
      "    accuracy                           0.09       500\n",
      "   macro avg       0.05      0.50      0.08       500\n",
      "weighted avg       0.01      0.09      0.02       500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8162it [01:16, 107.30it/s]\n",
      "500it [00:00, 3175.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/20], Train Loss: 0.0001, Test Accuracy: 9.40%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      1.00      0.17        46\n",
      "           1       1.00      0.00      0.00       454\n",
      "\n",
      "    accuracy                           0.09       500\n",
      "   macro avg       0.55      0.50      0.09       500\n",
      "weighted avg       0.92      0.09      0.02       500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8162it [01:12, 112.40it/s]\n",
      "500it [00:00, 3778.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/20], Train Loss: 0.0001, Test Accuracy: 9.20%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      1.00      0.17        46\n",
      "           1       0.00      0.00      0.00       454\n",
      "\n",
      "    accuracy                           0.09       500\n",
      "   macro avg       0.05      0.50      0.08       500\n",
      "weighted avg       0.01      0.09      0.02       500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8162it [01:12, 112.48it/s]\n",
      "500it [00:00, 2957.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/20], Train Loss: 0.0001, Test Accuracy: 9.20%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      1.00      0.17        46\n",
      "           1       0.00      0.00      0.00       454\n",
      "\n",
      "    accuracy                           0.09       500\n",
      "   macro avg       0.05      0.50      0.08       500\n",
      "weighted avg       0.01      0.09      0.02       500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8162it [01:19, 102.35it/s]\n",
      "500it [00:00, 3209.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/20], Train Loss: 0.0003, Test Accuracy: 9.20%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      1.00      0.17        46\n",
      "           1       0.00      0.00      0.00       454\n",
      "\n",
      "    accuracy                           0.09       500\n",
      "   macro avg       0.05      0.50      0.08       500\n",
      "weighted avg       0.01      0.09      0.02       500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8162it [01:14, 110.17it/s]\n",
      "500it [00:00, 3196.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/20], Train Loss: 0.0001, Test Accuracy: 9.20%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      1.00      0.17        46\n",
      "           1       0.00      0.00      0.00       454\n",
      "\n",
      "    accuracy                           0.09       500\n",
      "   macro avg       0.05      0.50      0.08       500\n",
      "weighted avg       0.01      0.09      0.02       500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8162it [01:11, 113.62it/s]\n",
      "500it [00:00, 3216.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/20], Train Loss: 0.0001, Test Accuracy: 9.20%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      1.00      0.17        46\n",
      "           1       0.00      0.00      0.00       454\n",
      "\n",
      "    accuracy                           0.09       500\n",
      "   macro avg       0.05      0.50      0.08       500\n",
      "weighted avg       0.01      0.09      0.02       500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8162it [01:14, 109.87it/s]\n",
      "500it [00:00, 2460.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/20], Train Loss: 0.0001, Test Accuracy: 9.20%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      1.00      0.17        46\n",
      "           1       0.00      0.00      0.00       454\n",
      "\n",
      "    accuracy                           0.09       500\n",
      "   macro avg       0.05      0.50      0.08       500\n",
      "weighted avg       0.01      0.09      0.02       500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8162it [01:13, 111.21it/s]\n",
      "500it [00:00, 3207.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/20], Train Loss: 0.0001, Test Accuracy: 9.20%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      1.00      0.17        46\n",
      "           1       0.00      0.00      0.00       454\n",
      "\n",
      "    accuracy                           0.09       500\n",
      "   macro avg       0.05      0.50      0.08       500\n",
      "weighted avg       0.01      0.09      0.02       500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8162it [01:11, 114.43it/s]\n",
      "500it [00:00, 3136.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/20], Train Loss: 0.0001, Test Accuracy: 9.20%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      1.00      0.17        46\n",
      "           1       0.00      0.00      0.00       454\n",
      "\n",
      "    accuracy                           0.09       500\n",
      "   macro avg       0.05      0.50      0.08       500\n",
      "weighted avg       0.01      0.09      0.02       500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8162it [01:10, 115.18it/s]\n",
      "500it [00:00, 1869.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/20], Train Loss: 0.0001, Test Accuracy: 9.20%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      1.00      0.17        46\n",
      "           1       0.00      0.00      0.00       454\n",
      "\n",
      "    accuracy                           0.09       500\n",
      "   macro avg       0.05      0.50      0.08       500\n",
      "weighted avg       0.01      0.09      0.02       500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8162it [01:27, 93.15it/s] \n",
      "500it [00:00, 2736.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/20], Train Loss: 0.0001, Test Accuracy: 9.20%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      1.00      0.17        46\n",
      "           1       0.00      0.00      0.00       454\n",
      "\n",
      "    accuracy                           0.09       500\n",
      "   macro avg       0.05      0.50      0.08       500\n",
      "weighted avg       0.01      0.09      0.02       500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8162it [01:09, 117.00it/s]\n",
      "500it [00:00, 2943.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/20], Train Loss: 0.0001, Test Accuracy: 9.20%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      1.00      0.17        46\n",
      "           1       0.00      0.00      0.00       454\n",
      "\n",
      "    accuracy                           0.09       500\n",
      "   macro avg       0.05      0.50      0.08       500\n",
      "weighted avg       0.01      0.09      0.02       500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8162it [01:09, 116.80it/s]\n",
      "500it [00:00, 3215.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/20], Train Loss: 0.0001, Test Accuracy: 9.20%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      1.00      0.17        46\n",
      "           1       0.00      0.00      0.00       454\n",
      "\n",
      "    accuracy                           0.09       500\n",
      "   macro avg       0.05      0.50      0.08       500\n",
      "weighted avg       0.01      0.09      0.02       500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8162it [01:06, 123.44it/s]\n",
      "500it [00:00, 3213.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/20], Train Loss: 0.0001, Test Accuracy: 9.20%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      1.00      0.17        46\n",
      "           1       0.00      0.00      0.00       454\n",
      "\n",
      "    accuracy                           0.09       500\n",
      "   macro avg       0.05      0.50      0.08       500\n",
      "weighted avg       0.01      0.09      0.02       500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8162it [01:07, 121.12it/s]\n",
      "500it [00:00, 3698.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/20], Train Loss: 0.0001, Test Accuracy: 9.20%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      1.00      0.17        46\n",
      "           1       0.00      0.00      0.00       454\n",
      "\n",
      "    accuracy                           0.09       500\n",
      "   macro avg       0.05      0.50      0.08       500\n",
      "weighted avg       0.01      0.09      0.02       500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8162it [01:07, 121.01it/s]\n",
      "500it [00:00, 2874.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/20], Train Loss: 0.0001, Test Accuracy: 9.20%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      1.00      0.17        46\n",
      "           1       0.00      0.00      0.00       454\n",
      "\n",
      "    accuracy                           0.09       500\n",
      "   macro avg       0.05      0.50      0.08       500\n",
      "weighted avg       0.01      0.09      0.02       500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8162it [01:05, 124.91it/s]\n",
      "500it [00:00, 3677.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/20], Train Loss: 0.0001, Test Accuracy: 9.20%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      1.00      0.17        46\n",
      "           1       0.00      0.00      0.00       454\n",
      "\n",
      "    accuracy                           0.09       500\n",
      "   macro avg       0.05      0.50      0.08       500\n",
      "weighted avg       0.01      0.09      0.02       500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8162it [01:05, 124.47it/s]\n",
      "500it [00:00, 3224.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/20], Train Loss: 0.0001, Test Accuracy: 9.20%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      1.00      0.17        46\n",
      "           1       0.00      0.00      0.00       454\n",
      "\n",
      "    accuracy                           0.09       500\n",
      "   macro avg       0.05      0.50      0.08       500\n",
      "weighted avg       0.01      0.09      0.02       500\n",
      "\n",
      "FOLD 1\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8162it [01:06, 123.07it/s]\n",
      "500it [00:00, 3205.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Train Loss: 0.0001, Test Accuracy: 9.20%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      1.00      0.17        46\n",
      "           1       0.00      0.00      0.00       454\n",
      "\n",
      "    accuracy                           0.09       500\n",
      "   macro avg       0.05      0.50      0.08       500\n",
      "weighted avg       0.01      0.09      0.02       500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8162it [01:06, 122.11it/s]\n",
      "500it [00:00, 3198.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20], Train Loss: 0.0001, Test Accuracy: 9.40%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      1.00      0.17        46\n",
      "           1       1.00      0.00      0.00       454\n",
      "\n",
      "    accuracy                           0.09       500\n",
      "   macro avg       0.55      0.50      0.09       500\n",
      "weighted avg       0.92      0.09      0.02       500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8162it [01:05, 124.15it/s]\n",
      "500it [00:00, 3755.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/20], Train Loss: 0.0001, Test Accuracy: 9.20%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      1.00      0.17        46\n",
      "           1       0.00      0.00      0.00       454\n",
      "\n",
      "    accuracy                           0.09       500\n",
      "   macro avg       0.05      0.50      0.08       500\n",
      "weighted avg       0.01      0.09      0.02       500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8162it [01:11, 114.72it/s]\n",
      "500it [00:00, 2530.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/20], Train Loss: 0.0001, Test Accuracy: 9.40%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      1.00      0.17        46\n",
      "           1       1.00      0.00      0.00       454\n",
      "\n",
      "    accuracy                           0.09       500\n",
      "   macro avg       0.55      0.50      0.09       500\n",
      "weighted avg       0.92      0.09      0.02       500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8162it [01:18, 103.39it/s]\n",
      "500it [00:00, 3226.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/20], Train Loss: 0.0001, Test Accuracy: 9.40%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      1.00      0.17        46\n",
      "           1       1.00      0.00      0.00       454\n",
      "\n",
      "    accuracy                           0.09       500\n",
      "   macro avg       0.55      0.50      0.09       500\n",
      "weighted avg       0.92      0.09      0.02       500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8162it [01:16, 106.75it/s]\n",
      "500it [00:00, 2923.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/20], Train Loss: 0.0001, Test Accuracy: 9.20%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      1.00      0.17        46\n",
      "           1       0.00      0.00      0.00       454\n",
      "\n",
      "    accuracy                           0.09       500\n",
      "   macro avg       0.05      0.50      0.08       500\n",
      "weighted avg       0.01      0.09      0.02       500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8162it [01:17, 105.54it/s]\n",
      "500it [00:00, 3169.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/20], Train Loss: 0.0001, Test Accuracy: 9.40%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      1.00      0.17        46\n",
      "           1       1.00      0.00      0.00       454\n",
      "\n",
      "    accuracy                           0.09       500\n",
      "   macro avg       0.55      0.50      0.09       500\n",
      "weighted avg       0.92      0.09      0.02       500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8162it [01:18, 103.79it/s]\n",
      "500it [00:00, 3038.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/20], Train Loss: 0.0001, Test Accuracy: 9.40%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      1.00      0.17        46\n",
      "           1       1.00      0.00      0.00       454\n",
      "\n",
      "    accuracy                           0.09       500\n",
      "   macro avg       0.55      0.50      0.09       500\n",
      "weighted avg       0.92      0.09      0.02       500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8162it [01:19, 103.30it/s]\n",
      "500it [00:00, 3120.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/20], Train Loss: 0.0001, Test Accuracy: 9.40%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      1.00      0.17        46\n",
      "           1       1.00      0.00      0.00       454\n",
      "\n",
      "    accuracy                           0.09       500\n",
      "   macro avg       0.55      0.50      0.09       500\n",
      "weighted avg       0.92      0.09      0.02       500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8162it [01:18, 103.98it/s]\n",
      "500it [00:00, 2871.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/20], Train Loss: 0.0001, Test Accuracy: 9.40%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      1.00      0.17        46\n",
      "           1       1.00      0.00      0.00       454\n",
      "\n",
      "    accuracy                           0.09       500\n",
      "   macro avg       0.55      0.50      0.09       500\n",
      "weighted avg       0.92      0.09      0.02       500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8162it [01:12, 112.86it/s]\n",
      "500it [00:00, 2963.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/20], Train Loss: 0.0001, Test Accuracy: 9.40%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      1.00      0.17        46\n",
      "           1       1.00      0.00      0.00       454\n",
      "\n",
      "    accuracy                           0.09       500\n",
      "   macro avg       0.55      0.50      0.09       500\n",
      "weighted avg       0.92      0.09      0.02       500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8162it [01:17, 104.66it/s]\n",
      "500it [00:00, 2683.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/20], Train Loss: 0.0001, Test Accuracy: 9.40%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      1.00      0.17        46\n",
      "           1       1.00      0.00      0.00       454\n",
      "\n",
      "    accuracy                           0.09       500\n",
      "   macro avg       0.55      0.50      0.09       500\n",
      "weighted avg       0.92      0.09      0.02       500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8162it [01:22, 98.86it/s] \n",
      "500it [00:00, 2856.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/20], Train Loss: 0.0001, Test Accuracy: 9.40%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      1.00      0.17        46\n",
      "           1       1.00      0.00      0.00       454\n",
      "\n",
      "    accuracy                           0.09       500\n",
      "   macro avg       0.55      0.50      0.09       500\n",
      "weighted avg       0.92      0.09      0.02       500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8162it [01:22, 98.52it/s] \n",
      "500it [00:00, 2844.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/20], Train Loss: 0.0001, Test Accuracy: 9.40%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      1.00      0.17        46\n",
      "           1       1.00      0.00      0.00       454\n",
      "\n",
      "    accuracy                           0.09       500\n",
      "   macro avg       0.55      0.50      0.09       500\n",
      "weighted avg       0.92      0.09      0.02       500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8162it [01:17, 105.05it/s]\n",
      "500it [00:00, 2856.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/20], Train Loss: 0.0001, Test Accuracy: 9.20%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      1.00      0.17        46\n",
      "           1       0.00      0.00      0.00       454\n",
      "\n",
      "    accuracy                           0.09       500\n",
      "   macro avg       0.05      0.50      0.08       500\n",
      "weighted avg       0.01      0.09      0.02       500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8162it [01:25, 95.00it/s] \n",
      "500it [00:00, 2646.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/20], Train Loss: 0.0001, Test Accuracy: 9.20%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      1.00      0.17        46\n",
      "           1       0.00      0.00      0.00       454\n",
      "\n",
      "    accuracy                           0.09       500\n",
      "   macro avg       0.05      0.50      0.08       500\n",
      "weighted avg       0.01      0.09      0.02       500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8162it [01:19, 103.22it/s]\n",
      "500it [00:00, 2574.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/20], Train Loss: 0.0001, Test Accuracy: 9.40%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      1.00      0.17        46\n",
      "           1       1.00      0.00      0.00       454\n",
      "\n",
      "    accuracy                           0.09       500\n",
      "   macro avg       0.55      0.50      0.09       500\n",
      "weighted avg       0.92      0.09      0.02       500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8162it [01:28, 92.46it/s] \n",
      "500it [00:00, 2682.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/20], Train Loss: 0.0001, Test Accuracy: 9.40%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      1.00      0.17        46\n",
      "           1       1.00      0.00      0.00       454\n",
      "\n",
      "    accuracy                           0.09       500\n",
      "   macro avg       0.55      0.50      0.09       500\n",
      "weighted avg       0.92      0.09      0.02       500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8162it [01:24, 96.85it/s] \n",
      "500it [00:00, 3001.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/20], Train Loss: 0.0001, Test Accuracy: 9.20%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      1.00      0.17        46\n",
      "           1       0.00      0.00      0.00       454\n",
      "\n",
      "    accuracy                           0.09       500\n",
      "   macro avg       0.05      0.50      0.08       500\n",
      "weighted avg       0.01      0.09      0.02       500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8162it [01:33, 87.35it/s] \n",
      "500it [00:00, 2699.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/20], Train Loss: 0.0001, Test Accuracy: 9.20%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      1.00      0.17        46\n",
      "           1       0.00      0.00      0.00       454\n",
      "\n",
      "    accuracy                           0.09       500\n",
      "   macro avg       0.05      0.50      0.08       500\n",
      "weighted avg       0.01      0.09      0.02       500\n",
      "\n",
      "FOLD 2\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8162it [01:34, 86.36it/s] \n",
      "500it [00:00, 3253.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Train Loss: 0.0001, Test Accuracy: 9.20%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      1.00      0.17        46\n",
      "           1       0.00      0.00      0.00       454\n",
      "\n",
      "    accuracy                           0.09       500\n",
      "   macro avg       0.05      0.50      0.08       500\n",
      "weighted avg       0.01      0.09      0.02       500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8162it [01:34, 85.95it/s] \n",
      "500it [00:00, 3116.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20], Train Loss: 0.0001, Test Accuracy: 9.20%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      1.00      0.17        46\n",
      "           1       0.00      0.00      0.00       454\n",
      "\n",
      "    accuracy                           0.09       500\n",
      "   macro avg       0.05      0.50      0.08       500\n",
      "weighted avg       0.01      0.09      0.02       500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8162it [01:40, 81.48it/s] \n",
      "500it [00:00, 2350.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/20], Train Loss: 0.0001, Test Accuracy: 9.20%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      1.00      0.17        46\n",
      "           1       0.00      0.00      0.00       454\n",
      "\n",
      "    accuracy                           0.09       500\n",
      "   macro avg       0.05      0.50      0.08       500\n",
      "weighted avg       0.01      0.09      0.02       500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8162it [01:30, 90.52it/s] \n",
      "500it [00:00, 2555.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/20], Train Loss: 0.0001, Test Accuracy: 9.20%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      1.00      0.17        46\n",
      "           1       0.00      0.00      0.00       454\n",
      "\n",
      "    accuracy                           0.09       500\n",
      "   macro avg       0.05      0.50      0.08       500\n",
      "weighted avg       0.01      0.09      0.02       500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8162it [01:29, 91.54it/s] \n",
      "500it [00:00, 3107.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/20], Train Loss: 0.0001, Test Accuracy: 9.20%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      1.00      0.17        46\n",
      "           1       0.00      0.00      0.00       454\n",
      "\n",
      "    accuracy                           0.09       500\n",
      "   macro avg       0.05      0.50      0.08       500\n",
      "weighted avg       0.01      0.09      0.02       500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8162it [01:31, 89.54it/s] \n",
      "500it [00:00, 2441.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/20], Train Loss: 0.0001, Test Accuracy: 9.20%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      1.00      0.17        46\n",
      "           1       0.00      0.00      0.00       454\n",
      "\n",
      "    accuracy                           0.09       500\n",
      "   macro avg       0.05      0.50      0.08       500\n",
      "weighted avg       0.01      0.09      0.02       500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8162it [01:25, 95.77it/s] \n",
      "500it [00:00, 2622.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/20], Train Loss: 0.0001, Test Accuracy: 9.20%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      1.00      0.17        46\n",
      "           1       0.00      0.00      0.00       454\n",
      "\n",
      "    accuracy                           0.09       500\n",
      "   macro avg       0.05      0.50      0.08       500\n",
      "weighted avg       0.01      0.09      0.02       500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8162it [01:39, 82.19it/s] \n",
      "500it [00:00, 2534.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/20], Train Loss: 0.0001, Test Accuracy: 9.20%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      1.00      0.17        46\n",
      "           1       0.00      0.00      0.00       454\n",
      "\n",
      "    accuracy                           0.09       500\n",
      "   macro avg       0.05      0.50      0.08       500\n",
      "weighted avg       0.01      0.09      0.02       500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8162it [01:13, 110.79it/s]\n",
      "500it [00:00, 3172.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/20], Train Loss: 0.0001, Test Accuracy: 9.20%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      1.00      0.17        46\n",
      "           1       0.00      0.00      0.00       454\n",
      "\n",
      "    accuracy                           0.09       500\n",
      "   macro avg       0.05      0.50      0.08       500\n",
      "weighted avg       0.01      0.09      0.02       500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8162it [01:12, 112.72it/s]\n",
      "500it [00:00, 3454.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/20], Train Loss: 0.0001, Test Accuracy: 9.20%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      1.00      0.17        46\n",
      "           1       0.00      0.00      0.00       454\n",
      "\n",
      "    accuracy                           0.09       500\n",
      "   macro avg       0.05      0.50      0.08       500\n",
      "weighted avg       0.01      0.09      0.02       500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8162it [01:13, 110.91it/s]\n",
      "500it [00:00, 3145.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/20], Train Loss: 0.0001, Test Accuracy: 9.20%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      1.00      0.17        46\n",
      "           1       0.00      0.00      0.00       454\n",
      "\n",
      "    accuracy                           0.09       500\n",
      "   macro avg       0.05      0.50      0.08       500\n",
      "weighted avg       0.01      0.09      0.02       500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8162it [01:17, 105.22it/s]\n",
      "500it [00:00, 3200.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/20], Train Loss: 0.0001, Test Accuracy: 9.20%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      1.00      0.17        46\n",
      "           1       0.00      0.00      0.00       454\n",
      "\n",
      "    accuracy                           0.09       500\n",
      "   macro avg       0.05      0.50      0.08       500\n",
      "weighted avg       0.01      0.09      0.02       500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8162it [01:40, 81.38it/s] \n",
      "500it [00:00, 3589.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/20], Train Loss: 0.0001, Test Accuracy: 9.20%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      1.00      0.17        46\n",
      "           1       0.00      0.00      0.00       454\n",
      "\n",
      "    accuracy                           0.09       500\n",
      "   macro avg       0.05      0.50      0.08       500\n",
      "weighted avg       0.01      0.09      0.02       500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8162it [01:20, 101.04it/s]\n",
      "500it [00:00, 2940.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/20], Train Loss: 0.0001, Test Accuracy: 9.20%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      1.00      0.17        46\n",
      "           1       0.00      0.00      0.00       454\n",
      "\n",
      "    accuracy                           0.09       500\n",
      "   macro avg       0.05      0.50      0.08       500\n",
      "weighted avg       0.01      0.09      0.02       500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8162it [01:10, 116.32it/s]\n",
      "500it [00:00, 3058.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/20], Train Loss: 0.0001, Test Accuracy: 9.20%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      1.00      0.17        46\n",
      "           1       0.00      0.00      0.00       454\n",
      "\n",
      "    accuracy                           0.09       500\n",
      "   macro avg       0.05      0.50      0.08       500\n",
      "weighted avg       0.01      0.09      0.02       500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8162it [01:09, 116.92it/s]\n",
      "500it [00:00, 3096.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/20], Train Loss: 0.0001, Test Accuracy: 9.20%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      1.00      0.17        46\n",
      "           1       0.00      0.00      0.00       454\n",
      "\n",
      "    accuracy                           0.09       500\n",
      "   macro avg       0.05      0.50      0.08       500\n",
      "weighted avg       0.01      0.09      0.02       500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8162it [01:08, 120.02it/s]\n",
      "500it [00:00, 2969.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/20], Train Loss: 0.0001, Test Accuracy: 9.20%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      1.00      0.17        46\n",
      "           1       0.00      0.00      0.00       454\n",
      "\n",
      "    accuracy                           0.09       500\n",
      "   macro avg       0.05      0.50      0.08       500\n",
      "weighted avg       0.01      0.09      0.02       500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8162it [01:08, 119.57it/s]\n",
      "500it [00:00, 3061.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/20], Train Loss: 0.0001, Test Accuracy: 9.20%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      1.00      0.17        46\n",
      "           1       0.00      0.00      0.00       454\n",
      "\n",
      "    accuracy                           0.09       500\n",
      "   macro avg       0.05      0.50      0.08       500\n",
      "weighted avg       0.01      0.09      0.02       500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8162it [01:13, 111.47it/s]\n",
      "500it [00:00, 2928.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/20], Train Loss: 0.0001, Test Accuracy: 9.20%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      1.00      0.17        46\n",
      "           1       0.00      0.00      0.00       454\n",
      "\n",
      "    accuracy                           0.09       500\n",
      "   macro avg       0.05      0.50      0.08       500\n",
      "weighted avg       0.01      0.09      0.02       500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8162it [01:18, 104.46it/s]\n",
      "500it [00:00, 2128.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/20], Train Loss: 0.0001, Test Accuracy: 9.20%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      1.00      0.17        46\n",
      "           1       0.00      0.00      0.00       454\n",
      "\n",
      "    accuracy                           0.09       500\n",
      "   macro avg       0.05      0.50      0.08       500\n",
      "weighted avg       0.01      0.09      0.02       500\n",
      "\n",
      "FOLD 3\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8162it [01:15, 107.56it/s]\n",
      "500it [00:00, 3080.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Train Loss: 0.0001, Test Accuracy: 9.20%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      1.00      0.17        46\n",
      "           1       0.00      0.00      0.00       454\n",
      "\n",
      "    accuracy                           0.09       500\n",
      "   macro avg       0.05      0.50      0.08       500\n",
      "weighted avg       0.01      0.09      0.02       500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8162it [01:12, 111.87it/s]\n",
      "500it [00:00, 3097.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20], Train Loss: 0.0001, Test Accuracy: 9.20%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      1.00      0.17        46\n",
      "           1       0.00      0.00      0.00       454\n",
      "\n",
      "    accuracy                           0.09       500\n",
      "   macro avg       0.05      0.50      0.08       500\n",
      "weighted avg       0.01      0.09      0.02       500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8162it [01:13, 111.75it/s]\n",
      "500it [00:00, 2065.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/20], Train Loss: 0.0001, Test Accuracy: 9.20%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      1.00      0.17        46\n",
      "           1       0.00      0.00      0.00       454\n",
      "\n",
      "    accuracy                           0.09       500\n",
      "   macro avg       0.05      0.50      0.08       500\n",
      "weighted avg       0.01      0.09      0.02       500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8162it [01:13, 110.73it/s]\n",
      "500it [00:00, 3058.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/20], Train Loss: 0.0001, Test Accuracy: 9.20%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      1.00      0.17        46\n",
      "           1       0.00      0.00      0.00       454\n",
      "\n",
      "    accuracy                           0.09       500\n",
      "   macro avg       0.05      0.50      0.08       500\n",
      "weighted avg       0.01      0.09      0.02       500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8162it [01:15, 108.06it/s]\n",
      "500it [00:00, 2918.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/20], Train Loss: 0.0001, Test Accuracy: 9.20%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      1.00      0.17        46\n",
      "           1       0.00      0.00      0.00       454\n",
      "\n",
      "    accuracy                           0.09       500\n",
      "   macro avg       0.05      0.50      0.08       500\n",
      "weighted avg       0.01      0.09      0.02       500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8162it [01:12, 111.96it/s]\n",
      "500it [00:00, 3677.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/20], Train Loss: 0.0001, Test Accuracy: 9.20%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      1.00      0.17        46\n",
      "           1       0.00      0.00      0.00       454\n",
      "\n",
      "    accuracy                           0.09       500\n",
      "   macro avg       0.05      0.50      0.08       500\n",
      "weighted avg       0.01      0.09      0.02       500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8162it [01:09, 116.85it/s]\n",
      "500it [00:00, 3052.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/20], Train Loss: 0.0001, Test Accuracy: 9.20%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      1.00      0.17        46\n",
      "           1       0.00      0.00      0.00       454\n",
      "\n",
      "    accuracy                           0.09       500\n",
      "   macro avg       0.05      0.50      0.08       500\n",
      "weighted avg       0.01      0.09      0.02       500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8162it [01:22, 99.45it/s] \n",
      "500it [00:00, 3148.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/20], Train Loss: 0.0001, Test Accuracy: 9.20%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      1.00      0.17        46\n",
      "           1       0.00      0.00      0.00       454\n",
      "\n",
      "    accuracy                           0.09       500\n",
      "   macro avg       0.05      0.50      0.08       500\n",
      "weighted avg       0.01      0.09      0.02       500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8162it [01:18, 103.82it/s]\n",
      "500it [00:00, 3118.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/20], Train Loss: 0.0001, Test Accuracy: 9.20%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      1.00      0.17        46\n",
      "           1       0.00      0.00      0.00       454\n",
      "\n",
      "    accuracy                           0.09       500\n",
      "   macro avg       0.05      0.50      0.08       500\n",
      "weighted avg       0.01      0.09      0.02       500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8162it [01:19, 102.94it/s]\n",
      "500it [00:00, 3126.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/20], Train Loss: 0.0001, Test Accuracy: 9.20%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      1.00      0.17        46\n",
      "           1       0.00      0.00      0.00       454\n",
      "\n",
      "    accuracy                           0.09       500\n",
      "   macro avg       0.05      0.50      0.08       500\n",
      "weighted avg       0.01      0.09      0.02       500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8162it [01:13, 111.09it/s]\n",
      "500it [00:00, 2994.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/20], Train Loss: 0.0001, Test Accuracy: 9.20%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      1.00      0.17        46\n",
      "           1       0.00      0.00      0.00       454\n",
      "\n",
      "    accuracy                           0.09       500\n",
      "   macro avg       0.05      0.50      0.08       500\n",
      "weighted avg       0.01      0.09      0.02       500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8162it [01:14, 110.27it/s]\n",
      "500it [00:00, 3153.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/20], Train Loss: 0.0001, Test Accuracy: 9.20%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      1.00      0.17        46\n",
      "           1       0.00      0.00      0.00       454\n",
      "\n",
      "    accuracy                           0.09       500\n",
      "   macro avg       0.05      0.50      0.08       500\n",
      "weighted avg       0.01      0.09      0.02       500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8162it [01:14, 109.61it/s]\n",
      "500it [00:00, 3021.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/20], Train Loss: 0.0001, Test Accuracy: 9.20%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      1.00      0.17        46\n",
      "           1       0.00      0.00      0.00       454\n",
      "\n",
      "    accuracy                           0.09       500\n",
      "   macro avg       0.05      0.50      0.08       500\n",
      "weighted avg       0.01      0.09      0.02       500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8162it [01:16, 106.33it/s]\n",
      "500it [00:00, 3601.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/20], Train Loss: 0.0001, Test Accuracy: 9.20%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      1.00      0.17        46\n",
      "           1       0.00      0.00      0.00       454\n",
      "\n",
      "    accuracy                           0.09       500\n",
      "   macro avg       0.05      0.50      0.08       500\n",
      "weighted avg       0.01      0.09      0.02       500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8162it [01:15, 108.81it/s]\n",
      "500it [00:00, 2997.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/20], Train Loss: 0.0001, Test Accuracy: 9.20%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      1.00      0.17        46\n",
      "           1       0.00      0.00      0.00       454\n",
      "\n",
      "    accuracy                           0.09       500\n",
      "   macro avg       0.05      0.50      0.08       500\n",
      "weighted avg       0.01      0.09      0.02       500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3905it [00:37, 103.73it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 47\u001b[0m\n\u001b[1;32m     44\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m     46\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 47\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# evaluate the model on the validation set\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from tqdm import tqdm\n",
    "\n",
    "model = Net(input_size=codebert_model.config.hidden_size, hidden_size=1000, num_classes=2)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "\n",
    "X = np.array(X_embeddings)\n",
    "y = np.array(Y)\n",
    "\n",
    "X = X[:5000]\n",
    "y = y[:5000]\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "\n",
    "smote = SMOTE()\n",
    "\n",
    "for fold, (train_ids, test_ids) in enumerate(kfold.split(X, y)):\n",
    "    print(f'FOLD {fold}')\n",
    "    print('--------------------------------')\n",
    "    \n",
    "    X_train, X_test = X[train_ids], X[test_ids]\n",
    "    y_train, y_test = y[train_ids], y[test_ids]\n",
    "\n",
    "    X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "    for epoch in range(20):\n",
    "        for i, (codes, labels) in tqdm(enumerate(zip(X_train, y_train))):\n",
    "            codes = torch.tensor(codes).unsqueeze(0)\n",
    "            labels = torch.tensor([labels]).long()\n",
    "\n",
    "            outputs = model(codes)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "        with torch.no_grad():\n",
    "            for i, (codes, labels) in tqdm(enumerate(zip(X_test, y_test))):\n",
    "\n",
    "                codes = torch.tensor(codes).unsqueeze(0)\n",
    "                labels = torch.tensor([labels]).long()\n",
    "\n",
    "                outputs = model(codes)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                y_true.append(labels.item())\n",
    "                y_pred.append(predicted.item())\n",
    "\n",
    "        accuracy = 100 * correct / total\n",
    "        print ('Epoch [{}/{}], Train Loss: {:.4f}, Test Accuracy: {:.2f}%'.format(epoch+1, 20, loss.item(), accuracy))\n",
    "        print(classification_report(y_true, y_pred, zero_division=0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
