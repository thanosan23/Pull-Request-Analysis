{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all the libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import polars as pl\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import polars as pl\n",
    "\n",
    "import xgboost as xgb\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data\n",
    "data = pd.read_csv(\"../data/pullreq_with_code.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the rows with no code\n",
    "data = data[data[\"added_code\"].astype(str) != \"None\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only get the merged data, and drop any data that have n/a as gender\n",
    "rejected_data = data.loc[data['merged_or_not'] == 0]\n",
    "rejected_data = rejected_data.loc[rejected_data['contrib_gender'].notna()]\n",
    "\n",
    "# drop the columns that are not needed\n",
    "rejected_data = rejected_data.drop(['ownername', 'reponame', 'id', 'project_id', 'github_id', 'creator_id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a label encoder to encode gender as 0 or 1\n",
    "le = LabelEncoder()\n",
    "le.fit(rejected_data['contrib_gender'])\n",
    "rejected_data['contrib_gender'] = le.transform(rejected_data['contrib_gender'])\n",
    "\n",
    "# sample the data to have equal number\n",
    "rejected_data_0 = rejected_data[rejected_data['contrib_gender'] == 0].sample(800)\n",
    "rejected_data_1 = rejected_data[rejected_data['contrib_gender'] == 1].sample(800)\n",
    "\n",
    "# concatenate the two dataframes\n",
    "rejected_data = pd.concat([rejected_data_0, rejected_data_1])\n",
    "\n",
    "# shuffle the data\n",
    "rejected_data = rejected_data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# get the x and y, x is the code, y is the gender\n",
    "X = rejected_data['added_code']\n",
    "Y = rejected_data['contrib_gender']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the tokenizer and model for codebert\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/codebert-base\")\n",
    "codebert_model = AutoModel.from_pretrained(\"microsoft/codebert-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1600/1600 [03:47<00:00,  7.02it/s]\n"
     ]
    }
   ],
   "source": [
    "# get the embeddings for each code\n",
    "X_embeddings = []\n",
    "for code in tqdm(X):\n",
    "    inputs = tokenizer(code, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    outputs = codebert_model(**inputs) # inputs = input_ids, attention_mask\n",
    "    X_embeddings.append(outputs.last_hidden_state[:, 0, :].detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape the embeddings\n",
    "X_embeddings = np.array(X_embeddings)\n",
    "X_embeddings = X_embeddings.reshape(-1, codebert_model.config.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train test val split\n",
    "train_ratio = 0.70\n",
    "test_ratio = 0.20\n",
    "val_ratio = 0.10\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_embeddings, Y, test_size=1-train_ratio)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=test_ratio/(val_ratio+test_ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to numpy arrays\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "X_val = np.array(X_val)\n",
    "y_val = np.array(y_val)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape the data\n",
    "X_train = X_train.reshape(-1, codebert_model.config.hidden_size)\n",
    "X_val = X_val.reshape(-1, codebert_model.config.hidden_size)\n",
    "X_test = X_test.reshape(-1, codebert_model.config.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a neural network model that takens in the code embeddings\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size) \n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)  \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Train Loss: 0.4756, Test Accuracy: 51.09%\n",
      "Epoch [2/100], Train Loss: 0.5119, Test Accuracy: 51.09%\n",
      "Epoch [3/100], Train Loss: 0.5110, Test Accuracy: 51.09%\n",
      "Epoch [4/100], Train Loss: 0.5107, Test Accuracy: 51.09%\n",
      "Epoch [5/100], Train Loss: 0.5106, Test Accuracy: 51.09%\n",
      "Epoch [6/100], Train Loss: 0.5106, Test Accuracy: 51.09%\n",
      "Epoch [7/100], Train Loss: 0.5106, Test Accuracy: 51.09%\n",
      "Epoch [8/100], Train Loss: 0.5106, Test Accuracy: 51.09%\n",
      "Epoch [9/100], Train Loss: 0.5106, Test Accuracy: 51.09%\n",
      "Epoch [10/100], Train Loss: 0.5106, Test Accuracy: 51.09%\n",
      "Epoch [11/100], Train Loss: 0.5106, Test Accuracy: 51.09%\n",
      "Epoch [12/100], Train Loss: 0.5106, Test Accuracy: 51.09%\n",
      "Epoch [13/100], Train Loss: 0.5106, Test Accuracy: 51.09%\n",
      "Epoch [14/100], Train Loss: 0.5106, Test Accuracy: 51.09%\n",
      "Epoch [15/100], Train Loss: 0.5106, Test Accuracy: 51.09%\n",
      "Epoch [16/100], Train Loss: 0.5106, Test Accuracy: 51.09%\n",
      "Epoch [17/100], Train Loss: 0.5106, Test Accuracy: 51.09%\n",
      "Epoch [18/100], Train Loss: 0.5106, Test Accuracy: 51.09%\n",
      "Epoch [19/100], Train Loss: 0.5106, Test Accuracy: 51.09%\n",
      "Epoch [20/100], Train Loss: 0.5106, Test Accuracy: 51.09%\n"
     ]
    }
   ],
   "source": [
    "# create the model\n",
    "model = Net(input_size=codebert_model.config.hidden_size, hidden_size=1000, num_classes=2)\n",
    "\n",
    "# create the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "\n",
    "# train the model\n",
    "for epoch in range(20):\n",
    "    for i, (codes, labels) in enumerate(zip(X_train, y_train)):\n",
    "        # get the code embeddings and labels\n",
    "        codes = torch.tensor(codes).unsqueeze(0)\n",
    "        labels = torch.tensor([labels]).long()\n",
    "        \n",
    "        # run gradient descent on the model\n",
    "        outputs = model(codes)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # evaluate the model on the validation set\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (codes, labels) in enumerate(zip(X_test, y_test)):\n",
    "            \n",
    "            codes = torch.tensor(codes).unsqueeze(0)\n",
    "            labels = torch.tensor([labels]).long()\n",
    "            \n",
    "            outputs = model(codes)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    # print the accuracy\n",
    "    accuracy = 100 * correct / total\n",
    "    print ('Epoch [{}/{}], Train Loss: {:.4f}, Test Accuracy: {:.2f}%'.format(epoch+1, 100, loss.item(), accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 48.12%\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model on the validation set\n",
    "y_true = []\n",
    "y_pred = []\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, (codes, labels) in enumerate(zip(X_val, y_val)):\n",
    "        codes = torch.tensor(codes).unsqueeze(0)\n",
    "        labels = torch.tensor([labels]).long()\n",
    "        \n",
    "        outputs = model(codes)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        y_true.extend(labels.tolist())\n",
    "        y_pred.extend(predicted.tolist())\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print ('Validation Accuracy: {:.2f}%'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.      0.48125]\n",
      "[0. 1.]\n",
      "[0.         0.64978903]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model on the test set\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "precision, recall, f1_score, _ = precision_recall_fscore_support(np.array(y_true), np.array(y_pred))\n",
    "print(precision)\n",
    "print(recall)\n",
    "print(f1_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
